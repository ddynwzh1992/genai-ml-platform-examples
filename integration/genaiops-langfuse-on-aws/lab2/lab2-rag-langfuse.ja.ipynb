{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ragas と Langfuse を使用した Retrieval-Augmented Generation (RAG) パイプラインの評価\n",
    "\n",
    "このノートブックでは、[RAGAS](https://docs.ragas.io/en/v0.1.21/index.html) などのオープンソースツールを使用して Retrieval-Augmented Generation (RAG) パイプラインの品質を評価する方法を探求し、[Langfuse](https://langfuse.com/) の機能を活用して、トレースとスパンで RAG パイプラインを管理およびトレースします。Amazon Bedrock ナレッジベースと RAG バッチ生成結果を作成して、オフライン評価とスコアリングを示します。\n",
    "\n",
    "> ℹ️ 注意：このノートブックでは、一部のステップでユーザー設定が必要です。\n",
    ">\n",
    "> セルでユーザー設定が必要な場合、👉 絵文字付きのこのコールアウトのようなメッセージが表示されます。\n",
    ">\n",
    "> 👉 絵文字付きの指示に注意を払い、コードセルを実行する前に AWS コンソールまたは対応するセルで設定を実行してください。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 前提条件\n",
    "\n",
    "> カーネルを選択していない場合は、右上隅にある「Select Kernel」ボタンをクリックし、Python Environmentsを選択して「.venv (Python 3.9.20) .venv/bin/python Recommended」を選択してください。\n",
    "\n",
    "> 各ノートブックセルを実行するには、Shift + Enterを押してください。\n",
    "\n",
    "> ℹ️ AWS が提供する一時アカウントを使用してインストラクター主導のワークショップに参加している場合は、これらの前提条件ステップを**スキップ**できます"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Amazon OpenSearch の追加権限\n",
    "\n",
    "このノートブックで手動の Amazon Bedrock Knowledge Bases セットアップ手順を完了するには、**AWS Console ユーザー/ロール**に以下が必要です：\n",
    "\n",
    "- [Amazon OpenSearch ベクターコレクションを操作する権限](https://docs.aws.amazon.com/opensearch-service/latest/developerguide/serverless-vector-search.html)\n",
    "- **IAM ロールの作成**とポリシーの添付を含む権限：`iam:AttachRolePolicy`、`iam:CreateRole`、`iam:DetachRolePolicy`、`iam:GetRole`、`iam:PassRole`、`iam:CreatePolicy`、`iam:CreatePolicyVersion`、および `iam:DeletePolicyVersion`。\n",
    "\n",
    "> ℹ️ **注意：** テストでは、上記のリンクされた `aoss` ポリシーステートメントのみを使用して Amazon Bedrock KB を作成しようとしたときに `NetworkError` の問題が発生しました。これは代わりに `*` に対して `aoss:*` を付与することで解決されましたが、本番環境で使用する前にこれらの権限を減らすことを検討する必要があります。\n",
    "\n",
    "[AWS Console for Identity and Access Management (IAM)](https://console.aws.amazon.com/iam/home?#/home) を参照して、ユーザーまたはロールに権限を付与してください。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 依存関係と環境変数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AWS ワークショップ環境を使用していない場合は、以下の行のコメントを外して依存関係をインストールしてください\n",
    "# %pip install langfuse datasets ragas python-dotenv langchain-aws boto3 --upgrade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".env ファイルで Langfuse プロジェクトと API キーをセットアップし、セルフホストまたはクラウドの Langfuse 環境に接続するための前提条件が完了していることを確認してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# すでに VS Code サーバーの .env で環境変数を定義している場合は、以下のセルはスキップしてください。\n",
    "# langfuse 用の環境変数を定義してください。\n",
    "# これらの値は Langfuse で API キーを作成する際に確認することができます。\n",
    "# import os\n",
    "# os.environ[\"LANGFUSE_SECRET_KEY\"] = \"xxxx\" # Langfuse プロジェクトのシークレットキー\n",
    "# os.environ[\"LANGFUSE_PUBLIC_KEY\"] = \"xxxx\" # Langfuse プロジェクトのパブリックキー\n",
    "# os.environ[\"LANGFUSE_HOST\"] = \"xxx\" # Langfuse ドメイン"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "詳細については [Langfuse ドキュメント](https://langfuse.com/docs/get-started) を確認してください。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 初期化と認証チェック\n",
    "以下のセルを実行して、共通ライブラリとクライアントを初期化してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from typing import Any\n",
    "\n",
    "# 外部の依存関係:\n",
    "import pandas as pd  # テーブルデータの操作用\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "\n",
    "load_dotenv(\"../.env\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Amazon Bedrock クライアントを初期化し、アカウントで利用可能なモデルを確認します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3  # AWS Python SDK 全般 (Amazon Bedrock を含む)\n",
    "\n",
    "\n",
    "# Amazon Bedrock の設定へのアクセスに使用\n",
    "bedrock = boto3.client(service_name=\"bedrock\", region_name=\"us-west-2\")\n",
    "\n",
    "bedrock_agent_runtime = boto3.client(service_name=\"bedrock-agent-runtime\", region_name=\"us-west-2\")\n",
    "\n",
    "# アカウントで利用可能なモデルを確認\n",
    "models = bedrock.list_inference_profiles()\n",
    "for model in models[\"inferenceProfileSummaries\"]:\n",
    "    print(model[\"inferenceProfileName\"] + \" - \" + model[\"inferenceProfileId\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Langfuse クライアントを初期化し、認証情報が有効であることを確認します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langfuse import Langfuse\n",
    "\n",
    "\n",
    "# langfuse クライアント\n",
    "langfuse = Langfuse()\n",
    "if langfuse.auth_check():\n",
    "    print(\"Langfuse は正しく設定されています\")\n",
    "    print(f\"Langfuse インスタンスへはこちらからアクセスできます: {os.environ['LANGFUSE_HOST']}\")\n",
    "else:\n",
    "    print(\"認証情報が見つからないか問題があります。.env ファイル内の Langfuse API キーとホストを確認してください。\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ナレッジベースのセットアップ\n",
    "次に、ユーザークエリに対して retrieval-augmented generation (RAG) を実行できるように、ドキュメントを Amazon S3 にアップロードし、ベクターストア（ナレッジベース）を作成します。以下のステップでは、以下を設定します：\n",
    "\n",
    "- ドキュメントコーパスを保存するための Amazon S3 `bucket_name`\n",
    "- アーティファクトが保存されるバケット内のフォルダプレフィッス。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from botocore.exceptions import ClientError\n",
    "\n",
    "\n",
    "botosess = boto3.Session(region_name=\"us-west-2\")\n",
    "region = botosess.region_name\n",
    "account_id = boto3.client(\"sts\").get_caller_identity()[\"Account\"]\n",
    "bucket_name = f\"eval-{account_id}-{region}\"\n",
    "s3_prefix = \"bedrock-rag-eval\"\n",
    "\n",
    "# S3 バケットが存在するかどうかを確認し、存在しない場合はバケットを作成\n",
    "s3 = boto3.client(\"s3\")\n",
    "try:\n",
    "    s3.head_bucket(Bucket=bucket_name)\n",
    "    print(f\"Bucket {bucket_name} exists\")\n",
    "except ClientError:\n",
    "    print(f\"Creating bucket {bucket_name}\")\n",
    "    s3.create_bucket(Bucket=bucket_name, CreateBucketConfiguration={\"LocationConstraint\": region})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Amazon S3 にドキュメントをアップロードする\n",
    "\n",
    "まず、サンプルドキュメントを Amazon S3 にアップロードする必要があります。以下のコードセルを実行するだけで完了します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_s3uri = f\"s3://{bucket_name}/{s3_prefix}/corpus\"\n",
    "print(f\"Syncing corpus to:\\n{corpus_s3uri}/\")\n",
    "\n",
    "# フォルダを S3 バケットに再帰的に同期するために AWS CLI を使用\n",
    "!aws s3 sync --quiet ./datasets/corpus {corpus_s3uri}/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AWS コンソールでナレッジベースを作成する\n",
    "> 👉 このセクションには、コードセルを実行するだけでなく、手動で実行する必要があるステップが含まれています！"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "テスト用の実際の Bedrock ナレッジベースを設定する最も簡単な方法は、**AWS コンソールを通じて手動で行う**ことです：\n",
    "\n",
    "1. まず、[Amazon Bedrock の AWS コンソール](https://console.aws.amazon.com/bedrock/home?#/knowledge-bases)を**開き**、左側のサイドバーメニューから *Orchestration > Knowledge bases* を選択します。以下に示すスクリーンショットを参照してください：\n",
    "\n",
    "    > ℹ️ UI の右上隅にある *AWS Region* が正しい (us-west-2 である) ことを**確認**してください\n",
    "\n",
    "![KB Console](images/bedrock-kbs/01-bedrock-kb-console.png \"Amazon Bedrock ナレッジベースの AWS コンソールのスクリーンショット、「Create knowledge base」アクションボタンを表示\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. **Create knowledge base** ボタンをクリックし、**Knowledge Base with vector store** を選択します。開く画面で：\n",
    "\n",
    "- **knowledge base name** には `example-squad-kb` と入力します\n",
    "- **knowledge base description** には、`Demo knowledge base for question answering evaluation` のようなものを入力できます\n",
    "- その他の設定はデフォルトのままにします（新しい実行ロールの作成を許可し、タグなし）\n",
    "- データソースとして Amazon S3 を選択してください（デフォルト）\n",
    "\n",
    "設定は以下のスクリーンショットのようになるはずです：\n",
    "\n",
    "![KB Basics](images/bedrock-kbs/02a-create-kb-basics.png \"Bedrock ナレッジベース作成ワークフローのステップ 1 のスクリーンショット：KB 名、説明、（新規作成）実行ロール、（空の）タグが設定されています。フォームの最後に「Next」ボタンが表示されています。\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. **Next** 画面で、S3 データソースを設定します。\n",
    "\n",
    "    データソースを S3 のままにして、前のステップで作成したバケットとプレフィックスを選択し、Amazon Bedrock のデフォルトのパーサーを使用します。\n",
    "\n",
    "![](images/bedrock-kbs/02b-create-kb-data-source.png \"Cohere Embed Multilingual 埋め込みモデルと quick-create vector store を含むナレッジベースのベクターインデックス設定のスクリーンショット。「Next」ボタンが表示されています。\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. **Next** 画面で、ベクターインデックスを設定します：\n",
    "\n",
    "    *embeddings model* には `Cohere Embed Multilingual` を選択します\n",
    "\n",
    "    > ℹ️ [Amazon Bedrock モデルアクセスコンソール](https://console.aws.amazon.com/bedrock/home?#/modelaccess) で、現在のリージョンでこのモデルへのアクセスを有効にしていることを**確認**してください。\n",
    "    >\n",
    "    > 必要に応じて、別の埋め込みモデルを選択することができます。\n",
    "\n",
    "    *Vector database* には `Quick create a new vector store` を選択します\n",
    "\n",
    "    この画面または [Amazon Bedrock 開発者ガイド](https://docs.aws.amazon.com/bedrock/latest/userguide/knowledge-base-setup.html) で、Amazon Bedrock ナレッジベースがサポートするさまざまなベクターストアに関する詳細情報を見つけることができます。このデフォルトオプションでは、新しい [Amazon OpenSearch Serverless](https://docs.aws.amazon.com/opensearch-service/latest/developerguide/serverless-overview.html) クラスターが作成されます\n",
    "\n",
    "    以下のように他の設定はデフォルトのままにし、次に進んでください：\n",
    "\n",
    "![](images/bedrock-kbs/02c-create-kb-index.png \"Cohere Embed Multilingual 埋め込みモデルと quick-create vector store を含むナレッジベースのベクターインデックス設定のスクリーンショット。「Next」ボタンが表示されています。\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. **Next** をクリックして設定を確認し、次に **Create knowledge base** をクリックしてプロセスを完了します。\n",
    "\n",
    "    > ⏰ 作成が完了するまでに **数分**かかる場合があります。上にスクロールすると進行状況インジケーターバナーが表示されるはずです。または別のタブで、[Amazon OpenSearch Serverless Collections コンソール](https://console.aws.amazon.com/aos/home?#opensearch/collections) を確認することもできます。ここでは、基盤となるベクターコレクションが作成されています。\n",
    "\n",
    "    ナレッジベースが正常に作成されると、以下に示すように詳細画面に移動します：\n",
    "\n",
    "![](images/bedrock-kbs/03-kb-detail-page.png \"作成された Amazon Bedrock ナレッジベースの詳細画面、作成成功バナーを表示。'Knowledge base overview'（KB ID、名前、その他の詳細を含む）、「Tags」（空）、「Data source」（1 つの Amazon S3 データソースがリストされている）、「Embeddings model」（Cohere Embed）のセクションが含まれ、右側には対話型の「Test knowledge base」チャットサイドバーがあり、一部のデータソースが同期されていないという警告が表示されています。\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. 先ほどの警告ボックスで述べたように、新しいナレッジベースには、データソースを**同期**するまでドキュメントは含まれません：\n",
    "\n",
    "    データソースリストで名前の左側にあるチェックボックスを選択して S3 データソースを**選択 (Select)** し、上にある**同期 (Sync)** ボタンをクリックして同期を開始します。\n",
    "\n",
    "    *Status* が数秒間 `Syncing` に変わった後、`Available` に戻ります\n",
    "\n",
    "![](images/bedrock-kbs/04a-kb-data-source-after-sync.png \"同期を実行した後の KB 'data source' セクションのスクリーンショット、データソースが選択され、ステータスが 'available' と表示されている\")\n",
    "</md>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "同期が完了すると、ナレッジベースは使用できるようになります。\n",
    "\n",
    "オプションとして、データソースをクリックして、期待通りに 20 個のファイルが `Added` されたかどうかを確認できます：\n",
    "\n",
    "<img src=\"images/bedrock-kbs/04b-kb-data-sync-details.png\" width=\"600\" alt=\"同期が正常に完了し、20 個のファイルが検出されてインデックスに追加され、0 個のファイルが失敗したことを示すデータソース詳細画面\"/>\n",
    "</md>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ナレッジベースのテスト\n",
    "\n",
    "大規模な評価について議論する前に、ナレッジベースが正しく機能しているか確認するためにテストクエリを実行しましょう。ナレッジベースの詳細ページに戻りましょう。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "例えば、以下のスクリーンショットでは、ページ上部の *Knowledge Base overview* パネルにナレッジベースIDが `Z746ERZP5X` であることがわかります（ご自身の *Knowledge Base ID* を確認してください）。\n",
    "\n",
    "![](images/bedrock-kbs/04c-kb-main-page.png \"ナレッジベースのメインページのスクリーンショット\")\n",
    "\n",
    "👉 以下のプレースホルダーをナレッジベースの固有IDに**置き換え**、以下のセルを実行して続行してください："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knowledge_base_id = \"<置き換える>\"  # Something like \"Z746ERZP5X\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the ID identified, you can use the Bedrock runtime [RetrieveAndGenerate API](https://docs.aws.amazon.com/bedrock/latest/APIReference/API_agent-runtime_RetrieveAndGenerate.html) to query your knowledge base."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Victoria 州の経済状況はどうですか？\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RetrieveAndGenerate API と Nova Pro モデルを使用してナレッジベースをクエリする\n",
    "rag_resp = bedrock_agent_runtime.retrieve_and_generate(\n",
    "    input={\"text\": query},\n",
    "    retrieveAndGenerateConfiguration={\n",
    "        \"knowledgeBaseConfiguration\": {\n",
    "            \"knowledgeBaseId\": knowledge_base_id,\n",
    "            \"modelArn\": f\"arn:aws:bedrock:us-west-2:{account_id}:inference-profile/us.amazon.nova-pro-v1:0\",\n",
    "        },\n",
    "        \"type\": \"KNOWLEDGE_BASE\",\n",
    "    },\n",
    "    # オプションのセッション ID は、フォローアップ質問の結果を改善するのに役立ちます：\n",
    "    # sessionId='string'\n",
    ")\n",
    "\n",
    "print(\"Plain text response:\")\n",
    "print(\"--------------------\")\n",
    "print(rag_resp[\"output\"][\"text\"], end=\"\\n\\n\\n\")\n",
    "\n",
    "print(\"Full API output:\")\n",
    "print(\"----------------\")\n",
    "rag_resp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上記のセルで出力したフルの API 応答に示されているように、`RetrieveAndGenerate` アクションは以下を提供します：\n",
    "\n",
    "- 最終的なテキスト回答\n",
    "- 検索エンジンからの `retrievedReferences`\n",
    "- テキスト回答の異なる部分で引用されるべき参照を特定する `citations`\n",
    "\n",
    "また、以下に示すように、API を通じて**検索のみ**を実行し、生成回答合成ステップをスキップすることも可能です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieve_resp = bedrock_agent_runtime.retrieve(\n",
    "    knowledgeBaseId=knowledge_base_id,\n",
    "    retrievalQuery={\"text\": query},\n",
    ")\n",
    "print(json.dumps(retrieve_resp[\"retrievalResults\"], indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 評価のためのデータセットと指標の設定\n",
    "\n",
    "### データセットの読み込み\n",
    "\n",
    "この例では、RAG システムにクエリを送信し、結果をキュレーションして、参照入出力ペアを持つデータセットを使用します。Langfuse から本番データを取得する方法については、以降のセクションを参照してください。\n",
    "\n",
    "このデータセットには次の列が含まれています：\n",
    "\n",
    "- `question`: list[str] - これらは、RAG パイプラインで評価される質問です。\n",
    "\n",
    "- `contexts`: list[list[str]] - 質問に答えるために LLM に渡されたコンテキスト。\n",
    "\n",
    "- `answer`: list[str] - RAG パイプラインから生成され、ユーザーに提供される回答。\n",
    "\n",
    "- `ground_truths`: list[list[str]] - 質問に対する真実の回答。ただし、オンライン評価では、このケースでは Ground Truth データにアクセスできないため、これを無視できます。\n",
    "\n",
    "このデータセットの詳細については、[Exploding Gradients Dataset](https://huggingface.co/datasets/explodinggradients/fiqa/viewer/ragas_eval) を参照してください。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "データセットをロードすることから始めましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "\n",
    "fiqa_eval = load_dataset(\"explodinggradients/fiqa\", \"ragas_eval\")[\"baseline\"]\n",
    "fiqa_eval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RAGAS 指標\n",
    "RAG システムの以下の側面を測定します。これらの指標は [RAGAS](https://docs.ragas.io/en/stable/concepts/metrics/available_metrics/) で定義されています：\n",
    "\n",
    "- [Faithfulness (忠実度)](https://docs.ragas.io/en/stable/concepts/metrics/available_metrics/faithfulness/)：これは、生成された回答の事実の一貫性を、与えられたコンテキストに対して測定します。\n",
    "- [Response relevancy (応答の関連性)](https://docs.ragas.io/en/stable/concepts/metrics/available_metrics/answer_relevance/)：Response Relevancy 指標は、応答がユーザー入力に対してどれだけ関連性があるかを測定します。\n",
    "- [Context precision (コンテキストの適合率)](https://docs.ragas.io/en/stable/concepts/metrics/available_metrics/context_precision/)：コンテキスト適合率は、コンテキストに存在するすべての Ground Truth の関連アイテムが高いランクにランク付けされているかどうかを評価する指標です。理想的には、すべての関連チャンクがトップランクに表示される必要があります。\n",
    "\n",
    "これらの指標とその仕組みについて詳しくは、[RAGAS ドキュメント](https://docs.ragas.io/en/stable/concepts/metrics/available_metrics/)をご覧ください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# メトリクスのインポート\n",
    "from ragas.metrics import (\n",
    "    Faithfulness,\n",
    "    LLMContextPrecisionWithoutReference,\n",
    "    ResponseRelevancy,\n",
    ")\n",
    "\n",
    "\n",
    "# 選択したメトリクス\n",
    "metrics = [\n",
    "    Faithfulness(),\n",
    "    ResponseRelevancy(),\n",
    "    LLMContextPrecisionWithoutReference(),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragas.metrics.base import MetricWithEmbeddings, MetricWithLLM\n",
    "from ragas.run_config import RunConfig\n",
    "\n",
    "\n",
    "# RAGAS メトリクスを初期化するユーティリティ関数\n",
    "def init_ragas_metrics(metrics, llm, embedding):\n",
    "    for metric in metrics:\n",
    "        if isinstance(metric, MetricWithLLM):\n",
    "            print(metric.name + \" llm\")\n",
    "            metric.llm = llm\n",
    "        if isinstance(metric, MetricWithEmbeddings):\n",
    "            print(metric.name + \" embedding\")\n",
    "            metric.embeddings = embedding\n",
    "        run_config = RunConfig()\n",
    "        metric.init(run_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "次に、選択した LLM と埋め込みモデルを使用して指標を初期化する必要があります。この例では、Amazon Bedrock Nova Pro モデルと Cohere 埋め込み英語モデルを使用し、`langchain-aws` ライブラリの便利なラッパーを使用します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_aws import BedrockEmbeddings, ChatBedrockConverse\n",
    "from ragas.embeddings import LangchainEmbeddingsWrapper\n",
    "from ragas.llms import LangchainLLMWrapper\n",
    "\n",
    "\n",
    "config = {\n",
    "    \"region_name\": \"us-west-2\",  # E.g. \"us-east-1\"\n",
    "    \"llm\": \"us.amazon.nova-pro-v1:0\",  # E.g Claude モデルなども利用可能 \"anthropic.claude-3-5-sonnet-20241022-v2:0\"\n",
    "    \"embeddings\": \"cohere.embed-english-v3\",  # E.g or \"amazon.titan-embed-text-v2:0\"\n",
    "    \"temperature\": 0.4,\n",
    "}\n",
    "\n",
    "evaluator_llm = LangchainLLMWrapper(\n",
    "    ChatBedrockConverse(\n",
    "        region_name=config[\"region_name\"],\n",
    "        base_url=f\"https://bedrock-runtime.{config['region_name']}.amazonaws.com\",\n",
    "        model=config[\"llm\"],\n",
    "        temperature=config[\"temperature\"],\n",
    "    )\n",
    ")\n",
    "\n",
    "evaluator_embeddings = LangchainEmbeddingsWrapper(\n",
    "    BedrockEmbeddings(\n",
    "        region_name=config[\"region_name\"],\n",
    "        model_id=config[\"embeddings\"],\n",
    "    )\n",
    ")\n",
    "\n",
    "init_ragas_metrics(\n",
    "    metrics,\n",
    "    llm=evaluator_llm,\n",
    "    embedding=evaluator_embeddings,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Langfuse で評価結果をトレースする\n",
    "\n",
    "RAGAS を使用してモデルベースの評価を行う方法は 2 つあります：\n",
    "1. すべてのトレースにスコアを付ける：これは、各トレース項目に対して評価を実行することを意味します。これにより、RAG パイプラインへの各呼び出しのパフォーマンスについてより良いアイデアが得られますが、コストに注意してください。\n",
    "\n",
    "2. サンプリングによるスコア付け：この方法では、定期的にトレースのランダムサンプルを取得し、それらにスコアを付けます。これによりコストが削減され、アプリのパフォーマンスの概算が得られますが、重要なサンプルを見逃す可能性があります。\n",
    "\n",
    "この例では、事前構築されたデータセットと Amazon Bedrock Knowlegebase を使用した RAG パイプラインを使用して、両方のソリューションを試します。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### すべてのトレースにスコアを付ける\n",
    "\n",
    "単一のトレースの小さな例を取り上げ、RAGAS でどのようにスコア付けできるかを見てみましょう。まず、選択した指標でトレースにスコアを付けるためのユーティリティ関数を定義します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragas.dataset_schema import SingleTurnSample\n",
    "\n",
    "\n",
    "async def score_with_ragas(query, chunks, answer, metrics):\n",
    "    scores = {}\n",
    "    for metric in metrics:\n",
    "        sample = SingleTurnSample(\n",
    "            user_input=query,\n",
    "            retrieved_contexts=chunks,\n",
    "            response=answer,\n",
    "        )\n",
    "        print(f\"{metric.name} 計算中...\")\n",
    "        scores[metric.name] = await metric.single_turn_ascore(sample)\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### サンプルデータセット項目のスコアリング\n",
    "\n",
    "各リクエストでスコアを計算します。以下では、以下のステップを実行するダミーアプリケーションを説明します：\n",
    "\n",
    "- ユーザーから質問を取得する\n",
    "- ユーザーの質問に答えるために使用できるデータベースまたはベクターストアからコンテキストを取得する\n",
    "- 質問とコンテキストを LLM に渡して回答を生成する\n",
    "\n",
    "この場合、Langfuse Python [低レベル SDK](https://langfuse.com/docs/sdk/python/low-level-sdk) を使用して、より詳細な制御でトレースにログを記録する使用方法を示しています。また、後続のセクションで [デコレータ](https://langfuse.com/docs/sdk/python/decorators) を使用した例を見たり、[langfuse ドキュメント](https://langfuse.com/docs/sdk/overview)で詳細を読むこともできます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 質問を受けたら新しいトレースを開始\n",
    "row = fiqa_eval[0]\n",
    "question = row[\"question\"]\n",
    "trace = langfuse.trace(name=\"rag-fiqa\")\n",
    "\n",
    "# 関連するチャンクを取得\n",
    "# chunks = get_similar_chunks(question)\n",
    "contexts = row[\"contexts\"]\n",
    "# スパンに渡す\n",
    "trace.span(name=\"retrieval\", input={\"question\": question}, output={\"contexts\": contexts})\n",
    "\n",
    "# LLM を使ってチャンクに基づいた回答を生成\n",
    "# answer = get_response_from_llm(question, chunks)\n",
    "answer = row[\"answer\"]\n",
    "trace.generation(\n",
    "    name=\"generation\",\n",
    "    input={\"question\": question, \"contexts\": contexts},\n",
    "    output={\"answer\": answer},\n",
    ")\n",
    "\n",
    "# 質問、コンテキスト、回答のタプルのスコアを計算\n",
    "ragas_scores = await score_with_ragas(question, contexts, answer, metrics)\n",
    "ragas_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    f\"Langfuse でトレースされていますが、スコアはまだついていません。Langfuse UI で確認できます:\\n{os.environ['LANGFUSE_HOST']}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以下のように実行することで、トレースにスコアを添付することができます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# スコアを送信\n",
    "for m in metrics:\n",
    "    trace.score(name=m.name, value=ragas_scores[m.name])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the score is attached\n",
    "\n",
    "![](images/bedrock-kbs/04e-langfuse-single-eval-trace-score.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RAG のスコアリング\n",
    "最初のセクションで Amazon Bedrock Knowledge Bases を設定済みなので、今度はテストデータセットに対してその結果の品質を**評価**し、高品質かつ低コストの構成に**最適化**するための手助けをします。\n",
    "\n",
    "まず、質問、参照回答、およびそのソースドキュメントのサンプルデータセットを読み込みます（このデータセットの準備方法の詳細については、[この GitHub](https://github.com/aws-samples/llm-evaluation-methodology/blob/main/datasets/Prepare-SQuAD.ipynb) を参照してください）："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_df = pd.read_json(\"datasets/qa.manifest.jsonl\", lines=True)\n",
    "dataset_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "このデータセットのレコードには以下が含まれます：\n",
    "\n",
    "- (`doc`) このサンプルに対するソースドキュメントの全文\n",
    "- (`doc_id`) ソースドキュメントの一意の識別子\n",
    "- (`question`) ユーザーが尋ねる質問\n",
    "- (`question_id`) 質問の一意の識別子\n",
    "- (`answers`) ドキュメントによってサポートされる（複数の可能性がある）参照「正解」のリスト"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[RAGAS の API リファレンス](https://docs.ragas.io/en/latest/references/evaluation.html)に示されているように、RAGAS 評価データセットのレコードには通常以下が含まれます：\n",
    "\n",
    "- 尋ねられた `question`\n",
    "- システムが生成した `answer`\n",
    "- 答えの根拠となった実際のテキスト `contexts`（つまり、検索エンジンによって取得されたドキュメントテキストのスニペット）\n",
    "- `ground_truth` の答え\n",
    "\n",
    "ここでは、`@observe()` デコレータを使用して、Langfuse Python SDK で [Langfuse トラッキング](https://langfuse.com/docs/tracing) を RAG パイプラインに統合します。\n",
    "\n",
    "以下に示すように、Amazon Bedrock KB の取得および生成パイプラインで例の質問を実行し、メトリクスを計算する準備ができた参照を抽出できます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langfuse.decorators import langfuse_context, observe\n",
    "\n",
    "\n",
    "@observe(name=\"Knowledge Base Retrieve and Generate\")\n",
    "def retrieve_and_generate(\n",
    "    question: str,\n",
    "    kb_id: str,\n",
    "    generate_model_arn: str = f\"arn:aws:bedrock:us-west-2:{account_id}:inference-profile/us.amazon.nova-pro-v1:0\",\n",
    "    **kwargs,\n",
    "):\n",
    "    rag_resp = bedrock_agent_runtime.retrieve_and_generate(\n",
    "        input={\"text\": question},\n",
    "        retrieveAndGenerateConfiguration={\n",
    "            \"knowledgeBaseConfiguration\": {\n",
    "                \"knowledgeBaseId\": kb_id,\n",
    "                \"modelArn\": generate_model_arn,\n",
    "            },\n",
    "            \"type\": \"KNOWLEDGE_BASE\",\n",
    "        },\n",
    "    )\n",
    "    answer = rag_resp[\"output\"][\"text\"]\n",
    "\n",
    "    # ネストされた引用文献からフラットな引用文献リストを取得 -> retrievedReferences:\n",
    "    all_refs = [r for cite in rag_resp[\"citations\"] for r in cite[\"retrievedReferences\"]]\n",
    "    contexts = [r[\"content\"][\"text\"] for r in all_refs]\n",
    "    ref_s3uris = [r[\"location\"][\"s3Location\"][\"uri\"] for r in all_refs]\n",
    "    # マッピング e.g. 's3://.../doc_id.txt' -> 'doc_id':\n",
    "    ref_ids = [uri.rpartition(\"/\")[2].rpartition(\".\")[0] for uri in ref_s3uris]\n",
    "\n",
    "    # トレースする追加のデータを記録\n",
    "    langfuse_context.update_current_observation(\n",
    "        input={\"question\": question, \"contexts\": contexts},\n",
    "        output=answer,\n",
    "        model=\"us.amazon.nova-pro-v1:0\",\n",
    "        session_id=\"kb-rag-session\",\n",
    "        tags=[\"dev\"],\n",
    "        metadata=kwargs,\n",
    "    )\n",
    "\n",
    "    # 独立したスコアリングのためにトレース ID を取得\n",
    "    trace_id = langfuse_context.get_current_trace_id()\n",
    "    return {\n",
    "        \"answer\": answer,\n",
    "        \"retrieved_doc_ids\": ref_ids,\n",
    "        \"retrieved_doc_texts\": contexts,\n",
    "        \"trace_id\": trace_id,\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "リクエストが来たら RAG を実行し、結果をすぐにスコアリングします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from asyncio import run\n",
    "\n",
    "from langfuse.decorators import observe\n",
    "\n",
    "\n",
    "@observe(name=\"Knowledge Base Pipeline\")\n",
    "def rag_pipeline(\n",
    "    question,\n",
    "    user_id: str | None = None,\n",
    "    session_id: str | None = None,\n",
    "    kb_id: str | None = None,\n",
    "    metrics: Any | None = None,\n",
    "):\n",
    "    generated_answer = retrieve_and_generate(\n",
    "        question=question,\n",
    "        kb_id=kb_id,\n",
    "        kwargs={\"database\": \"Bedrock Knowledge Base\", \"kb_id\": kb_id},\n",
    "    )\n",
    "    contexts = generated_answer[\"retrieved_doc_texts\"]\n",
    "    answer = generated_answer[\"answer\"]\n",
    "    trace_id = generated_answer[\"trace_id\"]\n",
    "\n",
    "    score = run(score_with_ragas(question, contexts, answer=answer, metrics=metrics))\n",
    "    langfuse_context.update_current_trace(\n",
    "        user_id=user_id,\n",
    "        session_id=session_id,\n",
    "        tags=[\"dev\"],\n",
    "    )\n",
    "    for s in score:\n",
    "        langfuse.score(name=s, value=score[s], trace_id=trace_id)\n",
    "    return generated_answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = rag_pipeline(dataset_df.iloc[0][\"question\"], kb_id=knowledge_base_id, metrics=metrics)\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### サンプリングしてスコアを付ける\n",
    "\n",
    "すべてのプロダクショントレースにスコアを付けることは、アプリケーションのアーキテクチャーやトラフィックによっては時間がかかり、コストがかかる場合があります。その場合は、サンプリング手法を採用すると良いでしょう。バッチ処理を実行するタイムスライスと、そのタイムスライスからサンプリングするトレースの数を決定します。データセットを作成し、`ragas.evaluate` を呼び出して結果を分析します。\n",
    "\n",
    "これを定期的に実行して、タイムスライス間でスコアがどのように変化しているかを追跡し、不一致がないかを確認できます。\n",
    "\n",
    "先ほど `retrieve_and_generate()` 関数によって生成された既存の結果を評価します。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "まず、データセットの最初の 10 問に対して RAG を実行し、10 個のプロダクショントレースをシミュレートします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_generated_outputs = [\n",
    "    retrieve_and_generate(\n",
    "        question=rec.question,\n",
    "        kb_id=knowledge_base_id,\n",
    "        kwargs={\"database\": \"Bedrock Knowledge Base\", \"kb_id\": knowledge_base_id},\n",
    "    )\n",
    "    for _, rec in dataset_df.head(10).iterrows()\n",
    "]\n",
    "rag_generated_outputs[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Langfuse にアップロードされた結果は、以下の便利な関数を使って必要に応じて取り出すことができます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langfuse.api.resources.commons.types.trace_with_details import TraceWithDetails\n",
    "\n",
    "\n",
    "def get_traces(\n",
    "    limit: int = 5,\n",
    "    name: str | None = None,\n",
    "    user_id: str | None = None,\n",
    "    session_id: str | None = None,\n",
    "    from_timestamp: str | None = None,\n",
    "    to_timestamp: str | None = None,\n",
    ") -> list[TraceWithDetails]:\n",
    "    \"\"\"与えられたフィルターにマッチするトレースをLangfuseにクエリする。\n",
    "    詳細は https://langfuse.com/docs/query-traces を確認。\"\"\"\n",
    "\n",
    "    all_data = []\n",
    "    page = 1\n",
    "\n",
    "    while True:\n",
    "        response = langfuse.fetch_traces(\n",
    "            page=page,\n",
    "            name=name,\n",
    "            user_id=user_id,\n",
    "            session_id=session_id,\n",
    "            from_timestamp=from_timestamp,\n",
    "            to_timestamp=to_timestamp,\n",
    "        )\n",
    "        if not response.data:\n",
    "            break\n",
    "        page += 1\n",
    "        all_data.extend(response.data)\n",
    "        if len(all_data) > limit:\n",
    "            break\n",
    "\n",
    "    return all_data[:limit]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import sample\n",
    "\n",
    "\n",
    "NUM_TRACES_TO_SAMPLE = 3\n",
    "traces = get_traces(name=\"Knowledge Base Retrieve and Generate\", limit=10)\n",
    "if len(traces) > NUM_TRACES_TO_SAMPLE: # noqa: SIM108\n",
    "    traces_sample = sample(traces, NUM_TRACES_TO_SAMPLE)\n",
    "else:\n",
    "    traces_sample = traces\n",
    "\n",
    "print(f\"{len(traces)} 件のフィルターされたトレースから {len(traces_sample)} 件のトレースをサンプリングしました。\")\n",
    "for trace in traces_sample:\n",
    "    print(f\"Trace ID: {trace.id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "次に、バッチを作成してスコアを付けましょう。RAGAS は、huggingface のデータセットオブジェクトを使用してデータセットを構築し、評価を実行します。これを独自のプロダクションデータで実行する場合は、適切なキーを使用してトレースから質問、コンテキスト、および回答を抽出してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# サンプルをスコア付け\n",
    "evaluation_batch = {\n",
    "    \"question\": [],\n",
    "    \"contexts\": [],\n",
    "    \"answer\": [],\n",
    "    \"trace_id\": [],\n",
    "}\n",
    "\n",
    "for sample in traces_sample:\n",
    "    evaluation_batch[\"question\"].append(sample.input[\"question\"])\n",
    "    evaluation_batch[\"contexts\"].append(sample.input[\"contexts\"])\n",
    "    evaluation_batch[\"answer\"].append(sample.output)\n",
    "    evaluation_batch[\"trace_id\"].append(sample.id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RAGAS evaluate 関数を使用して（単一ターンのやり取りではなく）データセット全体にスコアを付けます。詳細については、[RAGAS evaluate](https://docs.ragas.io/en/latest/references/evaluate/) を参照してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RAGAS evaluate を実行\n",
    "from datasets import Dataset\n",
    "from ragas import evaluate\n",
    "from ragas.metrics import Faithfulness, ResponseRelevancy\n",
    "\n",
    "\n",
    "ds = Dataset.from_dict(evaluation_batch)\n",
    "evals_results = evaluate(\n",
    "    ds,\n",
    "    llm=evaluator_llm,\n",
    "    embeddings=evaluator_embeddings,\n",
    "    metrics=[Faithfulness(), ResponseRelevancy()],\n",
    ")\n",
    "evals_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "これで完了です！一定期間にわたるスコアを確認できます。データフレームで結果をレンダリングして、スコアを確認しましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = evals_results.to_pandas()\n",
    "\n",
    "# 結果のデータフレームに Langfuse trace_id を追加\n",
    "df[\"trace_id\"] = ds[\"trace_id\"]\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "スコアを Langfuse にプッシュバックし、トレースに添付することもできます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _, row in df.iterrows():\n",
    "    for metric_name in [\"faithfulness\", \"answer_relevancy\"]:\n",
    "        langfuse.score(name=metric_name, value=row[metric_name], trace_id=row[\"trace_id\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Langfuse コンソールに戻って、トレースで更新されたスコアを確認できます。\n",
    "\n",
    "![](images/bedrock-kbs/score-with-sampling.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### おめでとうございます！\n",
    "ラボ 2 を無事終了しました。\n",
    "\n",
    "AWS イベントに参加している場合は、次のラボに進む前に、ワークショップスタジオに戻って追加の指示を確認ください。次のラボでは、モデルベースの評価とガードレールについて学習します。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
