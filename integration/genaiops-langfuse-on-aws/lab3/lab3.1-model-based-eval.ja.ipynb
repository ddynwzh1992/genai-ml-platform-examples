{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6d8b8be2-25d0-4fd8-adb3-57857424ed84",
   "metadata": {},
   "source": [
    "# ラボ 3.1: 外部評価パイプラインを使用して Langfuse トレースを評価する\n",
    "\n",
    "#### 外部評価パイプラインは、次の場合に役立ちます：\n",
    "- トレース評価のタイミングをより細かく制御できる。パイプラインを特定の時間に実行するようにスケジュールしたり、Webhook などのイベントベースのトリガーに応答させたりできる。\n",
    "- Langfuse UI で可能な範囲を超えたカスタム評価が必要な場合、カスタム評価に柔軟性を持たせることができる。\n",
    "- カスタム評価のバージョン管理\n",
    "- 既存の評価フレームワークと事前定義されたメトリクスを使用してデータを評価する機能\n",
    "\n",
    "このノートブックでは、以下の手順で外部評価パイプラインを実装する方法を学習します：\n",
    "1. モデルをテストするための合成データセットを作成する\n",
    "2. Langfuse クライアントを使用して、以前のモデル実行のトレースを収集およびフィルタリングする\n",
    "3. これらのトレースをオフラインで、かつ段階的に評価する\n",
    "4. 既存の Langfuse トレースにスコアを追加する"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "699cf5b2",
   "metadata": {},
   "source": [
    "## 前提条件\n",
    "\n",
    "> ℹ️ AWS が提供する一時アカウントを使用してインストラクター主導のワークショップに参加している場合は、**これらの前提条件の手順をスキップできます**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd76becf-bfb8-48d5-bc3b-ca6b29413351",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# AWS ワークショップ環境を使用していない場合は、以下の行のコメントを外して依存関係をインストールしてください\n",
    "# !pip install langfuse datasets ragas python-dotenv langchain-aws boto3 --upgrade\n",
    "!uv pip install --force-reinstall -U -r ../../../../requirements.txt --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e32f49e",
   "metadata": {},
   "source": [
    "セルフホストまたはクラウドの Langfuse 環境に接続します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ea0cbc1-7af1-4875-bd2a-0e17ff33cde5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# すでに VS Code サーバーの .env で環境変数を定義している場合は、以下のセルはスキップしてください。\n",
    "# langfuse 用の環境変数を定義してください。\n",
    "# これらの値は Langfuse で API キーを作成する際に確認することができます。\n",
    "# import os\n",
    "# os.environ[\"LANGFUSE_SECRET_KEY\"] = \"xxxx\" # Langfuse プロジェクトのシークレットキー\n",
    "# os.environ[\"LANGFUSE_PUBLIC_KEY\"] = \"xxxx\" # Langfuse プロジェクトのパブリックキー\n",
    "# os.environ[\"LANGFUSE_HOST\"] = \"xxx\" # Langfuse ドメイン"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a66d076",
   "metadata": {},
   "source": [
    "## 初期化と認証チェック\n",
    "以下のセルを実行して、共通ライブラリとクライアントを初期化してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea6967f-1a23-4029-b107-c38e2c74b53e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import boto3\n",
    "from langfuse.decorators import langfuse_context, observe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd5342ee",
   "metadata": {},
   "source": [
    "Amazon Bedrock クライアントを初期化し、アカウントで利用可能なモデルを確認します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9823c3f-bfc3-4507-bc14-42bccda623f3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Amazon Bedrock の設定にアクセスするために利用\n",
    "bedrock = boto3.client(service_name=\"bedrock\", region_name=\"us-west-2\")\n",
    "\n",
    "# このリージョンで Nova モデルが利用可能か確認\n",
    "models = bedrock.list_inference_profiles()\n",
    "nova_found = False\n",
    "for model in models[\"inferenceProfileSummaries\"]:\n",
    "    if (\n",
    "        \"Nova Pro\" in model[\"inferenceProfileName\"]\n",
    "        or \"Nova Lite\" in model[\"inferenceProfileName\"]\n",
    "        or \"Nova Micro\" in model[\"inferenceProfileName\"]\n",
    "    ):\n",
    "        print(f\"Found Nova model: {model['inferenceProfileName']} - {model['inferenceProfileId']}\")\n",
    "        nova_found = True\n",
    "if not nova_found:\n",
    "    raise ValueError(\"No Nova models found in available models. Please ensure you have access to Nova models.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "660e58d2",
   "metadata": {},
   "source": [
    "Langfuse クライアントを初期化し、認証情報が有効であることを確認します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa452fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langfuse import Langfuse\n",
    "\n",
    "\n",
    "# langfuse クライアント\n",
    "langfuse = Langfuse()\n",
    "if langfuse.auth_check():\n",
    "    print(\"Langfuse は正しく設定されています\")\n",
    "    print(f\"Langfuse インスタンスへはこちらからアクセスできます: {os.environ['LANGFUSE_HOST']}\")\n",
    "else:\n",
    "    print(\"認証情報が見つからないか問題があります。.env ファイル内の Langfuse API キーとホストを確認してください。\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b511da7",
   "metadata": {},
   "source": [
    "### Amazon Bedrock Converse API の Langfuse ラッパー"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b70cd7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(os.path.abspath(\"..\"))  # Add parent directory to path\n",
    "from config import MODEL_CONFIG\n",
    "from utils import converse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7ed397a-fd9c-47b1-8d42-cea1894ef30d",
   "metadata": {},
   "source": [
    "# 合成データの生成\n",
    "\n",
    "このノートブックでは、LLM を活用して、e コマースページで製品に関してアドバイスする際に使用できる製品説明を生成するユースケースを検討します。最初のステップでは、製品のリストを生成し、それぞれの製品に対して Amazon Nova Lite に簡潔な製品説明を生成するよう指示します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e45d951-8f92-4a0a-8755-bf3b58df7910",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 50 製品を生成するプロンプト\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"e コマースウェブサイトで販売されている 50 種類の異なる製品カテゴリーについて、\\\n",
    "        消費者にとって興味深い製品を 1 つずつ生成します。製品名は実際の販売されている製品を反映したものにする必要があります。 \\\n",
    "        50 の製品アイテムをカンマ区切りの値として生成します。製品名以外に追加の単語は生成しないでください。\",\n",
    "    },\n",
    "]\n",
    "\n",
    "# Nova Lite モデルの API 呼び出し\n",
    "model_response = converse(messages=messages, **MODEL_CONFIG[\"nova_lite\"])\n",
    "\n",
    "# 生成されたテキストを表示\n",
    "print(\"\\n[Response Content Text]\")\n",
    "print(model_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86b45f91-beb0-42ab-8741-1544027caa95",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# モデルが生成した出力を確認\n",
    "products = [item.strip() for item in model_response.split(\",\")]\n",
    "\n",
    "for prd in products:\n",
    "    print(prd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aa9f700-bd36-4625-b387-3ae16740a3d7",
   "metadata": {},
   "source": [
    "次に、各製品について Amazon Nova Lite を使用して製品説明を生成し、```@observe()``` デコレータを使用して Langfuse にトレースをキャプチャします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e11c48c0-9ed1-409b-8b20-b46404b264ef",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 各製品の製品説明を生成\n",
    "prompt_template = \"あなたはプロダクトマーケターであり、e コマースウェブサイトで \\\n",
    "製品を販売するために使用される詳細な製品説明を生成する必要があります。 \\\n",
    "説明のキャッチーなフレーズは、ソーシャルメディアキャンペーンにも使用されます。 \\\n",
    "製品説明から、お客様は製品が生活にどのように役立つかを理解できるだけでなく、 \\\n",
    "この会社を信頼できることも理解できるべきです。あなたの説明は楽しく魅力的です。 \\\n",
    "あなたの回答は最大 4 文にしてください。\"\n",
    "\n",
    "\n",
    "@observe(name=\"Batch Product Description Generation\")\n",
    "def main():\n",
    "    langfuse_context.update_current_trace(\n",
    "        user_id=\"nova-user-1\",\n",
    "        session_id=\"nova-batch-generation-session\",\n",
    "        tags=[\"lab3.1\"],\n",
    "    )\n",
    "\n",
    "    for product in products:\n",
    "        print(f\"Input: {product} の説明文を生成してください。\")\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": prompt_template},\n",
    "            {\"role\": \"user\", \"content\": f\"{product} の説明文を生成してください。\"},\n",
    "        ]\n",
    "        response = converse(messages, metadata={\"product\": product}, **MODEL_CONFIG[\"nova_lite\"])\n",
    "        print(f\"Output: {response} \\n\")\n",
    "\n",
    "\n",
    "main()\n",
    "\n",
    "langfuse_context.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63401ad3",
   "metadata": {},
   "source": [
    "これで、langfuse UI のトレースセクションにこれらの製品説明が表示されるはずです。\n",
    "\n",
    "![Traces collected from the LLM generations](./images/product_description_traces.png \"Langfuse Traces\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91c1d0dd-370e-4053-a90a-c3ddfb095677",
   "metadata": {},
   "source": [
    "このチュートリアルの目標は、モデルベースの評価パイプラインを構築する方法を示すことです。これらのパイプラインは、CI/CD 環境で実行されるか、異なるオーケストレーションされたコンテナサービスで実行されるでしょう。選択する環境に関係なく、常に 3 つの重要なステップが適用されます：\n",
    "\n",
    "1. トレースを取得：アプリケーショントレースを評価環境に取得する\n",
    "2. 評価を実行：任意の評価ロジックを適用する\n",
    "3. 結果を保存：評価の計算に使用した Langfuse トレースに評価を戻して添付する\n",
    "\n",
    "***\n",
    "目標：この評価パイプラインは、過去 24 時間のすべてのトレースに対して実行されます\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0762d57d-ad9d-4157-a055-4f1cd68bee0f",
   "metadata": {},
   "source": [
    "## 1. トレース の取得\n",
    "\n",
    "`fetch_traces()` 関数には、タグ、タイムスタンプなどでトレースにフィルターをかける引数があります。また、ページネーション用のサンプル数を選択することもできます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb9280ea-d355-40ee-ab59-b91715e16a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "\n",
    "\n",
    "now = datetime.now()\n",
    "last_24_hours = now - timedelta(days=1)\n",
    "\n",
    "traces_batch = langfuse.fetch_traces(\n",
    "    page=1,\n",
    "    limit=1,\n",
    "    tags=\"lab3.1\",\n",
    "    session_id=\"nova-batch-generation-session\",\n",
    "    from_timestamp=last_24_hours,\n",
    "    to_timestamp=datetime.now(),\n",
    ").data\n",
    "\n",
    "print(f\"Trace ID: {traces_batch[0].id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e9ce965",
   "metadata": {},
   "outputs": [],
   "source": [
    "observations = langfuse.fetch_observations(trace_id=traces_batch[0].id, type=\"GENERATION\").data\n",
    "observations[0].output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06ff8eea-302e-44ee-a4bf-7595c848f872",
   "metadata": {},
   "source": [
    "## 2. LLM-as-a-judge を使用したカテゴリ評価\n",
    "\n",
    "評価関数は入力としてトレースを受け取り、有効なスコアを出力します。\n",
    "LLM アプリケーションの出力を分析する際、読みやすさ、有用性などの定性的に定義された特性や、完全性などの幻覚を軽減するための測定値を評価したい場合があります。\n",
    "\n",
    "私たちは製品の説明を作成しており、顧客に響くものであることを確認するために、読みやすさを測定したいと考えています。LLM-as-a-judge の定義について詳しくは、[Amazon Bedrock 評価プロンプト](https://docs.aws.amazon.com/bedrock/latest/userguide/model-evaluation-type-judge-prompt.html) に定義されているジャッジベースの評価プロンプトをご覧ください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbe7fe3a-0ce0-408a-a68b-1b79a11aab29",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "template_readability = \"\"\"\n",
    "あなたは、与えられた指示に従って LLM の応答を評価できる役立つエージェントです。\n",
    "\n",
    "LLM によって生成された製品説明が与えられます。あなたの課題は、質問に対する LLM 応答の読みやすさを評価することです。つまり、一般的な読者が通常の読書速度で応答を理解しやすいかどうかを評価します。\n",
    "\n",
    "以下の尺度に基づいて、応答の読みやすさを評価してください。\n",
    "- unreadable: 応答はナンセンスであるか、通常の読者には理解できません。\n",
    "- poor readability: 応答は理解できますが、理解を非常に困難にする読みにくい要因がたくさんあります。\n",
    "- fair readability: 応答は理解できますが、読みにくい要因と読みやすい要因が混在しているため、平均的な読者はテキストを理解するためにある程度時間を費やす必要があります。\n",
    "- good readability: 読みにくい要因はほとんどありません。ほとんどが明確で構造化された文章です。難しい単語にはコンテキストが明確に示されている標準的な語彙が使われています。トピック文と補足説明が明確に組織化されています。平均的な読者は一度通して読めば理解できます。\n",
    "- excellent readability: 読みにくい要因はありません。文構造は一貫して明確、簡潔、かつ多様な表現が使われています。また、広く理解されている簡単な語彙が使われています。アイデアの間の移行がスムーズな論理的な構成になっています。平均的な読者は読み飛ばしても必要な点を理解できるかもしれません。\n",
    "\n",
    "評価が必要な製品説明は次のとおりです: {prd_desc}\n",
    "\n",
    "最初に応答の説明をし、次に最終的な回答を示してください。次の形式に従う必要があります。\n",
    "Explanation: [説明], Answer: [回答],\n",
    "ここで '[回答]' は以下のいずれかになります。\n",
    "```\n",
    "unreadable\n",
    "poor readability\n",
    "fair readability\n",
    "good readability\n",
    "excellent readability\n",
    "```\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "@observe(name=\"Readability Evaluation\")\n",
    "def generate_readability_score(trace_output):\n",
    "    prd_desc_readability = template_readability.format(prd_desc=trace_output)\n",
    "    # query = [f\"Rate the readability of product description: {traces_batch[1].output}\"]\n",
    "    readability_score = converse(\n",
    "        messages=[{\"role\": \"user\", \"content\": prd_desc_readability}], **MODEL_CONFIG[\"nova_pro\"]\n",
    "    )\n",
    "    explanation, score = readability_score.split(\"\\n\\n\")\n",
    "    return explanation, score\n",
    "\n",
    "\n",
    "print(f\"ユーザーのクエリ: {observations[0].input[1]['content']}\")\n",
    "print(f\"モデルの回答: {observations[0].output}\")\n",
    "explanation, score = generate_readability_score(observations[0].output)\n",
    "print(f\"読みやすさ: {score}, 説明: {explanation}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ffa4aea-f139-43db-8f81-ead648d05029",
   "metadata": {},
   "source": [
    "## 3. トレースに評価を追加\n",
    "\n",
    "読みやすさのスコアと説明を生成したので、Langfuse クライアントを使用して既存のトレースにスコアを追加できます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f936b040-4fff-47ae-91ef-cd5c16db3f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "langfuse.score(\n",
    "    trace_id=traces_batch[0].id,\n",
    "    observation_id=observations[0].id,\n",
    "    name=\"readability\",\n",
    "    value=score,\n",
    "    comment=explanation,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6a8fee5-a484-4a58-b0d0-72022bfc8f08",
   "metadata": {},
   "source": [
    "# すべてを組み合わせる\n",
    "\n",
    "1 つのトレースに対してこれを実行する方法を見てきました。過去 24 時間に収集されたすべてのトレースに対して実行する関数にまとめてみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0288a48c-8703-419c-99a7-a2fc1f3ac1fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "@observe(name=\"Batch Readability Evaluation\")\n",
    "def batch_evaluate():\n",
    "    langfuse_context.update_current_trace(\n",
    "        user_id=\"nova-user-1\",\n",
    "        session_id=\"nova-batch-evals-session\",\n",
    "        tags=[\"lab3.1\"],\n",
    "    )\n",
    "    traces_batch = langfuse.fetch_traces(\n",
    "        page=1,\n",
    "        limit=1,\n",
    "        tags=\"lab3.1\",\n",
    "        session_id=\"nova-batch-generation-session\",\n",
    "        from_timestamp=last_24_hours,\n",
    "        to_timestamp=datetime.now(),\n",
    "    ).data\n",
    "\n",
    "    observations = langfuse.fetch_observations(trace_id=traces_batch[0].id, type=\"GENERATION\").data\n",
    "\n",
    "    for observation in observations[-5:]:  # 時間の節約のために最新の 5 つのオブザベーションのみを評価\n",
    "        print(f\"Processing {observation.id}\")\n",
    "        if observation.output is None:\n",
    "            print(\n",
    "                f\"Warning: \\n Trace {observation.id} had no generated output, \\\n",
    "            it was skipped\"\n",
    "            )\n",
    "            continue\n",
    "        explanation, score = generate_readability_score(observation.output)\n",
    "        langfuse.score(\n",
    "            trace_id=traces_batch[0].id,\n",
    "            observation_id=observation.id,\n",
    "            name=\"readability\",\n",
    "            value=score,\n",
    "            comment=explanation,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3e60d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_evaluate()\n",
    "\n",
    "langfuse_context.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9d8ed8e-bfb4-471d-a085-47863214b5b1",
   "metadata": {},
   "source": [
    "#### パイプラインが正常に実行された場合、トレースにスコアが追加されているはずです\n",
    "\n",
    "![読みやすさのスコアが追加された Langfuse トレース](./images/scored_trace.png \"Langfuse でのスコア付きトレース\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fab301d0",
   "metadata": {},
   "source": [
    "### おめでとうございます\n",
    "ラボ 3.1 を無事終了しました。\n",
    "\n",
    "AWS イベントに参加している場合は、次のラボに進む前に、ワークショップスタジオに戻って追加の指示を受けてください。次のラボでは、GenAI ガードレールについて探求します。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc994cbe",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
